{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6977eca3-7760-47cd-a840-e8aa6ca34192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89d92d69-1974-4ac6-afa7-9288b56d022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sales_5000000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de65b363-7a6c-4bc5-8652-c2d16b4ac6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Order Date', 'Total Profit']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f0d72b3-bac5-499c-a000-107e4d4fc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order Date'] = pd.to_datetime(df['Order Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0fea6ac-76e6-4594-b05e-c913579db6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Order Date').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f208c525-747f-4526-9662-6e578079f65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>273270.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>12185.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>495008.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>13457.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>252651.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-10</th>\n",
       "      <td>12054.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-10</th>\n",
       "      <td>241155.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-10</th>\n",
       "      <td>162433.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-10</th>\n",
       "      <td>315571.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-10</th>\n",
       "      <td>220734.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Profit\n",
       "Order Date              \n",
       "2014-01-01     273270.24\n",
       "2014-01-01      12185.94\n",
       "2014-01-01     495008.80\n",
       "2014-01-01      13457.44\n",
       "2014-01-01     252651.48\n",
       "...                  ...\n",
       "2024-09-10      12054.82\n",
       "2024-09-10     241155.20\n",
       "2024-09-10     162433.49\n",
       "2024-09-10     315571.12\n",
       "2024-09-10     220734.80\n",
       "\n",
       "[5000000 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b21fb14-21bb-484d-816b-e5223c92a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = df.groupby('Order Date')['Total Profit'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1ea5427-9957-48a2-b0c9-775437e67ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_df = daily_df.resample('ME', on='Order Date')['Total Profit'].sum().reset_index()\n",
    "monthly_df.columns = ['Order Date', 'Total Profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9decbd8a-057a-4cb6-9b02-315f11739309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>1.556656e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>1.402973e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>1.556248e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>1.510544e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-31</td>\n",
       "      <td>1.559264e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>1.558589e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>1.506300e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>1.553073e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>1.558169e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>5.059861e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Order Date  Total Profit\n",
       "0   2014-01-31  1.556656e+10\n",
       "1   2014-02-28  1.402973e+10\n",
       "2   2014-03-31  1.556248e+10\n",
       "3   2014-04-30  1.510544e+10\n",
       "4   2014-05-31  1.559264e+10\n",
       "..         ...           ...\n",
       "124 2024-05-31  1.558589e+10\n",
       "125 2024-06-30  1.506300e+10\n",
       "126 2024-07-31  1.553073e+10\n",
       "127 2024-08-31  1.558169e+10\n",
       "128 2024-09-30  5.059861e+09\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55c126f1-f2da-402e-9191-5ea16958e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_df = monthly_df.loc[:127] #last row error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c343cd-8de4-4cbe-abb4-5d9791fa3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(monthly_df, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91a96dbf-4dd6-4609-8604-3b7ceed80bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_data[\"Total Profit\"] = scaler.fit_transform(train_data[[\"Total Profit\"]])\n",
    "test_data[\"Total Profit\"] = scaler.transform(test_data[[\"Total Profit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba8832b7-37fc-4f50-ba95-421e011be632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>0.921351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-28</td>\n",
       "      <td>0.048936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>0.919033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>0.659589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-31</td>\n",
       "      <td>0.936155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0.098940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>0.926551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>0.649426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>0.971595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>0.636426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Order Date  Total Profit\n",
       "0   2014-01-31      0.921351\n",
       "1   2014-02-28      0.048936\n",
       "2   2014-03-31      0.919033\n",
       "3   2014-04-30      0.659589\n",
       "4   2014-05-31      0.936155\n",
       "..         ...           ...\n",
       "97  2022-02-28      0.098940\n",
       "98  2022-03-31      0.926551\n",
       "99  2022-04-30      0.649426\n",
       "100 2022-05-31      0.971595\n",
       "101 2022-06-30      0.636426\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a23c5cef-110f-44da-970b-9cd6363734b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Total Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.928565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>0.951341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>0.641980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>0.949891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>0.656276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.951815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>0.936125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0.072866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>0.916363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>0.667901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>0.908180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>0.630438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>0.969304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>0.916389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>0.635010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>0.939296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>0.635705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.955723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>0.931468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>0.312044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0.923613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>0.627616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>0.932325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>0.635495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>0.901012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>0.929940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Order Date  Total Profit\n",
       "102 2022-07-31      0.928565\n",
       "103 2022-08-31      0.951341\n",
       "104 2022-09-30      0.641980\n",
       "105 2022-10-31      0.949891\n",
       "106 2022-11-30      0.656276\n",
       "107 2022-12-31      0.951815\n",
       "108 2023-01-31      0.936125\n",
       "109 2023-02-28      0.072866\n",
       "110 2023-03-31      0.916363\n",
       "111 2023-04-30      0.667901\n",
       "112 2023-05-31      0.908180\n",
       "113 2023-06-30      0.630438\n",
       "114 2023-07-31      0.969304\n",
       "115 2023-08-31      0.916389\n",
       "116 2023-09-30      0.635010\n",
       "117 2023-10-31      0.939296\n",
       "118 2023-11-30      0.635705\n",
       "119 2023-12-31      0.955723\n",
       "120 2024-01-31      0.931468\n",
       "121 2024-02-29      0.312044\n",
       "122 2024-03-31      0.923613\n",
       "123 2024-04-30      0.627616\n",
       "124 2024-05-31      0.932325\n",
       "125 2024-06-30      0.635495\n",
       "126 2024-07-31      0.901012\n",
       "127 2024-08-31      0.929940"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6daf9c98-f723-448b-8127-b050a172c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 12\n",
    "\n",
    "# Prepare data for model\n",
    "values_train = train_data[\"Total Profit\"].values\n",
    "values_test = test_data[\"Total Profit\"].values\n",
    "\n",
    "X_train, y_train = create_sequences(values_train, seq_length)\n",
    "X_test, y_test = create_sequences(values_test, seq_length)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0c25160-99ac-4928-b3c6-380497992e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 12, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bea5ecb5-3548-4dad-a5b0-2cf44fac5b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b83dc2d-2bb5-43ac-8d35-eedabe87039b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 8s 385ms/step - loss: 1.1873 - mae: 0.9406 - rmse: 1.1981 - val_loss: 0.7720 - val_mae: 0.7478 - val_rmse: 0.7720\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.1105 - mae: 0.8592 - rmse: 1.1110 - val_loss: 0.7391 - val_mae: 0.7135 - val_rmse: 0.7391\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9256 - mae: 0.7545 - rmse: 0.9274 - val_loss: 0.7123 - val_mae: 0.6855 - val_rmse: 0.7123\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9480 - mae: 0.7564 - rmse: 0.9381 - val_loss: 0.7059 - val_mae: 0.6788 - val_rmse: 0.7059\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.8662 - mae: 0.7006 - rmse: 0.8675 - val_loss: 0.7007 - val_mae: 0.6735 - val_rmse: 0.7007\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7889 - mae: 0.6694 - rmse: 0.7903 - val_loss: 0.6934 - val_mae: 0.6659 - val_rmse: 0.6934\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6788 - mae: 0.5564 - rmse: 0.6856 - val_loss: 0.6894 - val_mae: 0.6613 - val_rmse: 0.6894\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6897 - mae: 0.5561 - rmse: 0.6861 - val_loss: 0.6819 - val_mae: 0.6531 - val_rmse: 0.6819\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.7541 - mae: 0.6251 - rmse: 0.7513 - val_loss: 0.6706 - val_mae: 0.6412 - val_rmse: 0.6706\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6348 - mae: 0.5079 - rmse: 0.6319 - val_loss: 0.6628 - val_mae: 0.6330 - val_rmse: 0.6628\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.6545 - mae: 0.5268 - rmse: 0.6536 - val_loss: 0.6572 - val_mae: 0.6268 - val_rmse: 0.6572\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5790 - mae: 0.4925 - rmse: 0.5791 - val_loss: 0.6640 - val_mae: 0.6338 - val_rmse: 0.6640\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5486 - mae: 0.4365 - rmse: 0.5644 - val_loss: 0.6610 - val_mae: 0.6308 - val_rmse: 0.6610\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5737 - mae: 0.4710 - rmse: 0.5686 - val_loss: 0.6535 - val_mae: 0.6231 - val_rmse: 0.6535\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5251 - mae: 0.4180 - rmse: 0.5212 - val_loss: 0.6472 - val_mae: 0.6173 - val_rmse: 0.6472\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4896 - mae: 0.3830 - rmse: 0.4913 - val_loss: 0.6439 - val_mae: 0.6140 - val_rmse: 0.6439\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5371 - mae: 0.4331 - rmse: 0.5464 - val_loss: 0.6475 - val_mae: 0.6178 - val_rmse: 0.6475\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4951 - mae: 0.4059 - rmse: 0.4974 - val_loss: 0.6452 - val_mae: 0.6155 - val_rmse: 0.6452\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4410 - mae: 0.3629 - rmse: 0.4403 - val_loss: 0.6280 - val_mae: 0.5972 - val_rmse: 0.6280\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5006 - mae: 0.3915 - rmse: 0.4976 - val_loss: 0.6076 - val_mae: 0.5755 - val_rmse: 0.6076\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4932 - mae: 0.3862 - rmse: 0.5011 - val_loss: 0.5905 - val_mae: 0.5577 - val_rmse: 0.5905\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.4018 - mae: 0.3267 - rmse: 0.4009 - val_loss: 0.5820 - val_mae: 0.5485 - val_rmse: 0.5820\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4260 - mae: 0.3334 - rmse: 0.4200 - val_loss: 0.5771 - val_mae: 0.5430 - val_rmse: 0.5771\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4698 - mae: 0.3829 - rmse: 0.4653 - val_loss: 0.5756 - val_mae: 0.5411 - val_rmse: 0.5756\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4401 - mae: 0.3685 - rmse: 0.4472 - val_loss: 0.5682 - val_mae: 0.5333 - val_rmse: 0.5682\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4280 - mae: 0.3465 - rmse: 0.4293 - val_loss: 0.5369 - val_mae: 0.5006 - val_rmse: 0.5369\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4660 - mae: 0.3778 - rmse: 0.4575 - val_loss: 0.5135 - val_mae: 0.4796 - val_rmse: 0.5135\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3844 - mae: 0.3036 - rmse: 0.3921 - val_loss: 0.5202 - val_mae: 0.4862 - val_rmse: 0.5202\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4371 - mae: 0.3476 - rmse: 0.4313 - val_loss: 0.5170 - val_mae: 0.4838 - val_rmse: 0.5170\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3856 - mae: 0.3160 - rmse: 0.3766 - val_loss: 0.4974 - val_mae: 0.4658 - val_rmse: 0.4974\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4231 - mae: 0.3360 - rmse: 0.4112 - val_loss: 0.5060 - val_mae: 0.4740 - val_rmse: 0.5060\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3790 - mae: 0.3094 - rmse: 0.3851 - val_loss: 0.5182 - val_mae: 0.4857 - val_rmse: 0.5182\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.4322 - mae: 0.3352 - rmse: 0.4326 - val_loss: 0.5147 - val_mae: 0.4824 - val_rmse: 0.5147\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4441 - mae: 0.3556 - rmse: 0.4402 - val_loss: 0.5001 - val_mae: 0.4679 - val_rmse: 0.5001\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.4027 - mae: 0.3183 - rmse: 0.4000 - val_loss: 0.4722 - val_mae: 0.4400 - val_rmse: 0.4722\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3668 - mae: 0.3014 - rmse: 0.3606 - val_loss: 0.4372 - val_mae: 0.4044 - val_rmse: 0.4372\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3838 - mae: 0.3040 - rmse: 0.3891 - val_loss: 0.4021 - val_mae: 0.3687 - val_rmse: 0.4021\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3656 - mae: 0.2987 - rmse: 0.3616 - val_loss: 0.3825 - val_mae: 0.3475 - val_rmse: 0.3825\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3136 - mae: 0.2501 - rmse: 0.3212 - val_loss: 0.3720 - val_mae: 0.3352 - val_rmse: 0.3720\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3500 - mae: 0.2795 - rmse: 0.3468 - val_loss: 0.3949 - val_mae: 0.3620 - val_rmse: 0.3949\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3863 - mae: 0.3175 - rmse: 0.3900 - val_loss: 0.3939 - val_mae: 0.3603 - val_rmse: 0.3939\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3630 - mae: 0.2741 - rmse: 0.3595 - val_loss: 0.3430 - val_mae: 0.3055 - val_rmse: 0.3430\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3489 - mae: 0.2742 - rmse: 0.3464 - val_loss: 0.3041 - val_mae: 0.2661 - val_rmse: 0.3041\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3983 - mae: 0.3254 - rmse: 0.3979 - val_loss: 0.2728 - val_mae: 0.2321 - val_rmse: 0.2728\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3909 - mae: 0.3236 - rmse: 0.3862 - val_loss: 0.2543 - val_mae: 0.2251 - val_rmse: 0.2543\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4105 - mae: 0.3211 - rmse: 0.4146 - val_loss: 0.2577 - val_mae: 0.2297 - val_rmse: 0.2577\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3270 - mae: 0.2682 - rmse: 0.3284 - val_loss: 0.2784 - val_mae: 0.2412 - val_rmse: 0.2784\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3865 - mae: 0.3161 - rmse: 0.3832 - val_loss: 0.3046 - val_mae: 0.2589 - val_rmse: 0.3046\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3528 - mae: 0.2906 - rmse: 0.3483 - val_loss: 0.3415 - val_mae: 0.2970 - val_rmse: 0.3415\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3614 - mae: 0.2800 - rmse: 0.3589 - val_loss: 0.3519 - val_mae: 0.3073 - val_rmse: 0.3519\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3334 - mae: 0.2660 - rmse: 0.3305 - val_loss: 0.3089 - val_mae: 0.2645 - val_rmse: 0.3089\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3048 - mae: 0.2421 - rmse: 0.3028 - val_loss: 0.2658 - val_mae: 0.2320 - val_rmse: 0.2658\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3299 - mae: 0.2623 - rmse: 0.3422 - val_loss: 0.2629 - val_mae: 0.2306 - val_rmse: 0.2629\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3150 - mae: 0.2596 - rmse: 0.3162 - val_loss: 0.2719 - val_mae: 0.2361 - val_rmse: 0.2719\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3454 - mae: 0.2894 - rmse: 0.3458 - val_loss: 0.3011 - val_mae: 0.2581 - val_rmse: 0.3011\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2924 - mae: 0.2370 - rmse: 0.2940 - val_loss: 0.2835 - val_mae: 0.2410 - val_rmse: 0.2835\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3264 - mae: 0.2699 - rmse: 0.3180 - val_loss: 0.2688 - val_mae: 0.2307 - val_rmse: 0.2688\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2688 - mae: 0.2265 - rmse: 0.2703 - val_loss: 0.2433 - val_mae: 0.2142 - val_rmse: 0.2433\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2734 - mae: 0.2247 - rmse: 0.2766 - val_loss: 0.2547 - val_mae: 0.2214 - val_rmse: 0.2547\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2843 - mae: 0.2241 - rmse: 0.2846 - val_loss: 0.2636 - val_mae: 0.2299 - val_rmse: 0.2636\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.3119 - mae: 0.2534 - rmse: 0.3128 - val_loss: 0.2847 - val_mae: 0.2466 - val_rmse: 0.2847\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2820 - mae: 0.2233 - rmse: 0.2811 - val_loss: 0.2600 - val_mae: 0.2281 - val_rmse: 0.2600\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3452 - mae: 0.2765 - rmse: 0.3570 - val_loss: 0.2179 - val_mae: 0.1908 - val_rmse: 0.2179\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2698 - mae: 0.2247 - rmse: 0.2686 - val_loss: 0.2272 - val_mae: 0.1611 - val_rmse: 0.2272\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3112 - mae: 0.2509 - rmse: 0.3091 - val_loss: 0.1994 - val_mae: 0.1748 - val_rmse: 0.1994\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2834 - mae: 0.2234 - rmse: 0.2772 - val_loss: 0.2001 - val_mae: 0.1837 - val_rmse: 0.2001\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2472 - mae: 0.1919 - rmse: 0.2537 - val_loss: 0.2525 - val_mae: 0.2178 - val_rmse: 0.2525\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3059 - mae: 0.2549 - rmse: 0.3091 - val_loss: 0.2612 - val_mae: 0.2287 - val_rmse: 0.2612\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3130 - mae: 0.2503 - rmse: 0.3162 - val_loss: 0.2337 - val_mae: 0.2029 - val_rmse: 0.2337\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3016 - mae: 0.2523 - rmse: 0.3025 - val_loss: 0.2193 - val_mae: 0.1966 - val_rmse: 0.2193\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2594 - mae: 0.2039 - rmse: 0.2617 - val_loss: 0.2516 - val_mae: 0.2163 - val_rmse: 0.2516\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2771 - mae: 0.2235 - rmse: 0.2817 - val_loss: 0.2549 - val_mae: 0.2191 - val_rmse: 0.2549\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2693 - mae: 0.2255 - rmse: 0.2709 - val_loss: 0.2268 - val_mae: 0.2018 - val_rmse: 0.2268\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3041 - mae: 0.2390 - rmse: 0.3055 - val_loss: 0.2226 - val_mae: 0.1979 - val_rmse: 0.2226\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3130 - mae: 0.2424 - rmse: 0.3054 - val_loss: 0.2116 - val_mae: 0.1890 - val_rmse: 0.2116\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2391 - mae: 0.1918 - rmse: 0.2384 - val_loss: 0.1933 - val_mae: 0.1684 - val_rmse: 0.1933\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2914 - mae: 0.2417 - rmse: 0.2945 - val_loss: 0.1870 - val_mae: 0.1717 - val_rmse: 0.1870\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2899 - mae: 0.2387 - rmse: 0.2912 - val_loss: 0.1902 - val_mae: 0.1688 - val_rmse: 0.1902\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2762 - mae: 0.2176 - rmse: 0.2759 - val_loss: 0.1937 - val_mae: 0.1706 - val_rmse: 0.1937\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2568 - mae: 0.2106 - rmse: 0.2563 - val_loss: 0.1816 - val_mae: 0.1598 - val_rmse: 0.1816\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2227 - mae: 0.1757 - rmse: 0.2219 - val_loss: 0.1819 - val_mae: 0.1646 - val_rmse: 0.1819\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2594 - mae: 0.2123 - rmse: 0.2612 - val_loss: 0.2052 - val_mae: 0.1854 - val_rmse: 0.2052\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2658 - mae: 0.2027 - rmse: 0.2698 - val_loss: 0.2229 - val_mae: 0.1954 - val_rmse: 0.2229\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2263 - mae: 0.1781 - rmse: 0.2275 - val_loss: 0.2095 - val_mae: 0.1867 - val_rmse: 0.2095\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2384 - mae: 0.1905 - rmse: 0.2389 - val_loss: 0.1720 - val_mae: 0.1596 - val_rmse: 0.1720\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2322 - mae: 0.1811 - rmse: 0.2294 - val_loss: 0.1516 - val_mae: 0.1394 - val_rmse: 0.1516\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2565 - mae: 0.2079 - rmse: 0.2502 - val_loss: 0.1563 - val_mae: 0.1358 - val_rmse: 0.1563\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2516 - mae: 0.2096 - rmse: 0.2604 - val_loss: 0.1614 - val_mae: 0.1298 - val_rmse: 0.1614\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2677 - mae: 0.2105 - rmse: 0.2639 - val_loss: 0.1764 - val_mae: 0.1272 - val_rmse: 0.1764\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2600 - mae: 0.2046 - rmse: 0.2513 - val_loss: 0.1995 - val_mae: 0.1454 - val_rmse: 0.1995\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2466 - mae: 0.1989 - rmse: 0.2432 - val_loss: 0.1967 - val_mae: 0.1486 - val_rmse: 0.1967\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2539 - mae: 0.2110 - rmse: 0.2488 - val_loss: 0.1722 - val_mae: 0.1296 - val_rmse: 0.1722\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2281 - mae: 0.1666 - rmse: 0.2275 - val_loss: 0.1552 - val_mae: 0.1143 - val_rmse: 0.1552\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2461 - mae: 0.2069 - rmse: 0.2422 - val_loss: 0.1451 - val_mae: 0.1129 - val_rmse: 0.1451\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2268 - mae: 0.1854 - rmse: 0.2314 - val_loss: 0.1389 - val_mae: 0.1104 - val_rmse: 0.1389\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2438 - mae: 0.2015 - rmse: 0.2448 - val_loss: 0.1553 - val_mae: 0.1318 - val_rmse: 0.1553\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2215 - mae: 0.1829 - rmse: 0.2206 - val_loss: 0.1828 - val_mae: 0.1249 - val_rmse: 0.1828\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2457 - mae: 0.1833 - rmse: 0.2534 - val_loss: 0.2230 - val_mae: 0.1635 - val_rmse: 0.2230\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2502 - mae: 0.2000 - rmse: 0.2495 - val_loss: 0.1970 - val_mae: 0.1426 - val_rmse: 0.1970\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2122 - mae: 0.1654 - rmse: 0.2174 - val_loss: 0.1613 - val_mae: 0.1241 - val_rmse: 0.1613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build Improved BiLSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(100, return_sequences=True), input_shape=(seq_length, 1)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(100, return_sequences=True)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(50)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "model.compile(optimizer='adam', loss=rmse, metrics=['mae', rmse])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d9e6e23-b82c-4c26-95d9-f9aca20e5cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# Compute evaluation metrics (adding small constant to avoid division errors)\n",
    "mape = mean_absolute_percentage_error(y_test_inv + 1e-9, y_pred_inv + 1e-9) * 100\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "accuracy = 100 - mape  # Approximate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf54696c-34f7-41cb-8eb9-5d93e2672d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.55216388284694"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593df263-d0cb-492a-82b2-c1ca2972e77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
